---
title: "Monday July 15, 2024"
date_created: "2024-07-15T08:44:01"
date: "2024-07-15T08:44:07"
tags: 
  - "agenda"
publish: false
---

- [x] Wake up on time - 7:30
- [x] Shower in the morning
- [x] Meditate - 15 minutes
- [x] Healthy breakfast - oatmeal and pourover
- [x] Ready to work on time - 8:45
- [x] Bowel movement in the morning
- [] Go outside and enjoy nature - at least 30 minutes
- [] Call Shruthi and wish her a happy belated birthday
- [] Calisthenics - pushups: (14)
- [] Submit time hours for Influential
- [] Look for photographer for grad party

Today, I have a demo to give to Alyssa, Rose, Kat, William, and those in the data team who want to join. I want to make sure that Cyrus and I are on the same page completely with respect to what I will present and how I will do it.

- Sour plums and blueberry jam

Stick to what we presented last time. Ahead of time good examples. Some that aren't so good. What do these numbers represent. Are these correlated, not correlated? 

1.5 version:
  - extractive summarization
  - verticals expansion
  - Maybe replace Mobius?
  - Brand detection and named-entity recognition.

2 version:
  - Introducing image embeddings

POC that we want done by end of Friday. Get it ready for maybe next Monday. This POC would basically be the sample data to sagar, use that as an example to run through the processes. 

Get provisioned throughput setup. Cyrus will get Sagar's sample data into Unity Catalog, so then we can talk about hitting the button the generation. 

We need to discuss how many parameters and categories we want. Next Tuesday or Wednesday. 

Then we can say that we have verticals for each 100k posts. For 13k accounts we have summaries, and they are all stored in Unity catalog. We can pass that on no later to Wednesday to Sagar who will index, vectorize, and go into search. 

We can start helping Sagar figure out the best way to setup this POC. Surely Weaviate has some sort of frontend or interface to test search. 

Priorities today: 
  - Get the demo out of the way 
  - Parallelize as much as possible with the summary generation code 


# Virtual Scrum

Sushant:
  - Data team internal sync
  - Short and sweet demo with Alyssa, Kat, William, and Rose at noon
  - Parallelizing code to generate and evaluate summarizations (parallel model requests and preprocessing)Working with Ryan
  - Working with Ryan on-and-off to continue writing semantic search metrics white paper (Search Metrics - Research and Discovery Whitepaper on Confluence DS

Anj: 
  - Meeting went well and Mack was great. Snap stuff needs to get up and running. 


# Data Team Sync
- We need Demo Pro for the sampled network_account_id's. 
- Whatever we need to do in order to support the effort to show the demo on Monday, Tuesday, or Wednesday next week
- We have until August 9, which is when we go from having a sample version to a finalized thing.
- We have enough code to start conversations with frontend engineers.
- Need evaluation pipelines. Better CI/CD pipelines. This stuff can be started after August 9.


# Demo Feedback
- Make sure to curate good examples (rich bio with really good summary)
- Poor bio but still decent summary
- Hallucinations even with rich summaries. 
- Cyrus will prompt engineer the query inputs using the vector database
- Put it on a confluence page
- Tag the group in radius-search with examples setup 
- We'll return to the evaluation piece. 
- Look into deepeval. It's probably just a score aggregator. He wouldn't bring it up if it wasn't used by at least a few companies. Compare LLM as a judge that I generated and check the correlations. 
- If we can do all of this today, we can figure out if we want to parallelize these summaries 

- We use AI to parse out what's 
- Do discovery to figure out what are the "distributions" of metrics and categorizations

1) Find examples for Sagar and folks and put on radius-search
2) Discovery on Eval and deep-eval

Won't have to worry about token stuff in the future. 

Persist data to unity catalog. 

ML Flow will register experiments for me. Just have to do a. 
