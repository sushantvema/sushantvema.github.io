---
title: "Wednesday September 11th, 2024"
date: 2024-09-11T07:19:45
date_created: "2024-09-11T07:19:51"
author: Sushant Vema
publish: false
tags:
  - "agenda"
---

# Personal
- [] Pay Peralta Tuition
- [] Pay Berkeley Tuition
- [] Send email to Darshanji about stargazing

# Meetings
## Data Science Standup
- Ryan: Working on sample data annotation for finetuning
- Alex: Working on demo pro and mobius, which are both in development. Won't have ability to easily pull the data off of the snapshots. Overloaded production on Sunday morning. 
- Cyrus: Tested out the finetuned model. Less performant than pre finetuned model. The problem was that we're feeding results from the llama3.1 70b model which already struggles with some categories. So Ryan is wokring on putting together a 200 sample of classifications. Wrote out a batch inference script at the tail end of yesterday. Looks like there's a 15b token limit per day. Above our daily needs and backfill. 
- Taylor: Checked in the Terraform code into the Terraform repository. 
- Sagar: Made all of the changes to the data model as per discussions with the qdrant team. Queries work as expected. Both vectors work as expected. Lots of hybrid searches which looks good. Data pipeline is working locally. 
- Cyrus: Something about separating vetting from sourcing. What different things do we need to expose on the backend. This can be low priority and can be pushed into a future sprint. 
- Anj: Meeting with Databricks to tell them that we're going to skip their vector database. Likes the plan of getting the qdrant solutions architect to work with us. 
- Sagar: The hybrid cloud cluster is set up. Production will be a different configuration. Dev and QA is setup. Youtube data is all ingested there, not on local. 
- Cyrus: Are we going to incrementally increase the compute power as we add more platforms? We will need to bump up the power. 
- Steven: Sprint meetings will be 9 am from now on. 

## Databricks Checkin
### Genai stuff
- Debu Sinha: There's a product in Databricks called AI Gateway. Allows to manage access to any external model. Promises a unified API wrapping all external models. I told him that seems completely unnecessary â€“ we don't need a beautiful API, cost and time performance is much more important. I spent a few minutes describing the dataflow of how I'm using OpenAI Batch API for summarization right now, he wasn't familiar with that paradigm. 
- Debu Sinha
- Leadership is prepared to get as competitive as possible with costs for the databricks vector store. I gave a very brief summary about the state of our qdrant efforts right now, directed Mikaela to Cyrus and Sagar. 
### Alex and Ryan
- Ryan: Start setting up monitoring for all of the workflows. Might need to set up monitoring on every single table. What do we want to monitor? Workflow metrics or table metrics?
- Cluster health overview, job performance, data quality monitoring, model performance tracking. Basic dashboard setup to track ingestion stuff. How many records were created or updated in various tables. Now we want to move to the Delta Lakehouse Monitoring. 
- Tian: Lakehouse Monitoring. Create a table to monitor the data quality (snapshot of data profile). Inference profile to keep track of model performance. Find a particular table in unity catalogue. Data quality tab. 
- Alex: Monitoring end to end pipelines is through Delta Live Tables according to Tian. We want to monitor ingestion into bronze layer on the day to day. 
- Tian: Lakehouse monitoring is purpose-built for data monitoring. There are also system tables to monitor billing, system health, job cluster stuff etc. System table is the right way to monitor infrastructure stuff. Tables will have a Changed Data Feed on them to figure out how many new records are getting in. 
- Ryan: Need admin access for system tables?
- Alex: Got Ryan access to the billing tables. We found infrastructure related metrics in a few other systems tables. 
- Tian: Need to make an API call in the terminal in order to have the system tables enabled?
- Ryan: Discovered some configuration options for 
- Alex: Will eventually have a need for lakehouse monitoring for cached summarizations, to keep track of when items were last updated
- Tian: Might have to grant permissions to view data in dashboards by default. Default configuration might have no permissions for anyone else. 
- Tian: Sending some templates for monitoring and stuff. She has a template for monitoring SQL warehouses for sure, will check for cluster health. 

## Cyrus, Sushant, Ryan Checkin
- Cyrus: Some debugging shenanigans
- Ryan: Minimally viable dashboard for monitoring
- Cyrus: Some debugging shenanigans
Ryan: Minimally viable dashboard for monitoring
- Cyrus: Some debugging shenanigans
- Ryan: Minimally viable dashboard for monitoring. Serverless is turned off. 

## RPM DB API Key
RD-XyY5zI7mmkW2Kv7ffBmhs6LVnHrgUPiQv

## Frontend GraphQL Schema Meeting
- Anj wanted us to start working on playing around with an early version of the UI integration. 
- Qdrant has a javascript SDK but they don't have a GraphQL integration like the other Weaviate database which we were working with earlier.
- Choice is on Cody to find out the easiest way to integrate with the qdrant search piece
- Right now most of the backend services are in node.js
- Wants to avoid having to maintain Python microservices.
- We don't have to built a graphql backend. Best is if we have a node backend which prim system can hit.
- Sagar requested the domain. Cody will point us to the right Types from the schema.graphql file.
- All the
- Sagar is not convinced that the javascript flavor of qdrant will be able to handle complex queries.
- The query layer can be decoupled from the preprocessing layer. Cody asks if we can have it all in one python service or split into 2 services.
- Javascript layer or FastAPI layer
- Every one of their engineers is familiar with node. Aside from the data team, Cody is the only engineer with extensive knowledge about Python
- Node is not the right tool for ingestion and index configuration. It's not equipped, nor is the library designed for it. The query layer should be built in node, that's where we leverage the javascript library. 
- Rose met with Kareem a few days before. Don't know who our solutions architect is yet, contract is being signed. Will be coming over on Monday. Target is getting all paper work signed by this week / end of the week. 
- Ideally have these discussions sooner. Friday or next Monday meeting since Anj wants us to start experimenting on this
- Let Cody figure out who will implement backend stuff. In terms of modifying the model etc it will be Sagar. 
