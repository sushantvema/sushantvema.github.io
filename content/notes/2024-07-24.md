---
title: "Wednesday July 24, 2024"
---

Cyrus Sync:
  - Still working on getting ground truth process. Ran through AI and found that AI is more effective than humans
  - When AI and Ryan disagree
  - Some categories where the AI does better
  - Context window is exploding.
  - Additional usage of language that might impart biographical information
  - Final tally for the summaries
  - Might run the RAG pipeline again with three new queries
  - Will be appended and de-duplicated to the delta table
  - Continue working on the prompt engineering stuff.
  - Take the lead today on batch inference using provisioned throughput
  - Set it up for 24 hours from the point I'm ready.
  - Approaches:
    - Python SDK
    - MLflow library
  - 100, 500, 1000


- Tell Cyrus when PT is setup 

Data Team Weekly Sync:
  - We're not that far from getting the necessary pieces into the vector store
  - Anj wants to see what our next two weeks are looking like
  - Alex was able to bring all our data into raw S3 layer. 
  - Demo-pro and mobius data that needs to be indexed
  - Two big items that are left to be indexed and then the demo will be ready. 
  - Vertical classification and summaries. 
  - On that front, sent a complete set of retrieved and relevant posts to Sushant. Spent time ensuring that we've come to a consensus on metrics as well as ground truths. 
  - Going on in tandem with work on verticals. Biggest challenge is identifying the most cost effective model and protocol for serving. 
  - Cost effectiveness and performance. In terms of performance, there are 
  - Best approach to serving these models and how to use them. 
  - Spin up a serverless compute that databricks provides. Pick a scale and they take care of the rest. Scale down to zero when not in use. Only used for batching purposes. 
  - 9 million youtube posts we want to run. 50,000 limit per batch. Send them back to us before 24 hours. Right now provisioned youtube. Could actually host llama 3.1 8b which is more than enough for us. Host on EKS on AWS and will be cheap enough.   
  - Will we have a backend API for the vector database written. 
  - Two approaches. Weaviate already provides a Graphql client. Best case Cody can show on the UI. Worst case is that we will have a regression suite and show a metric-based approach to evaluating search. 
  - Want Kat et al. to be able to make these search calls. 
  - Anj wants an open endpoint for querying. 

Spun up an endpoint for llama3 8b instruct. Used minimum throughput level. 3.1 model didn't work because of accelerated concurrency configuration. 

Thinking of refactoring 
