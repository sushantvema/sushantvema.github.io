---
title: "November 19th, 2024"
date_created: "2024-11-19T13:59:00"
date: "2024-11-19T13:59:05"
publish: false
tags:
  - "agenda"
---

# Meetings

## DBRX Databricks Architecture Review - Dustin Vannoy
2024-11-19T13:59:58. Alex, Sushant, Mikaela, Dustin, 

Doing end to end testing of our production ETL. Each day has an incremental workload. Not a huge amount of data. In the process of doing end to end, testing out loading al of our data. 

There is a google doc listing all of the clusters we are using. 

MariaDB -> S3 landing zone. -> bronze layer with structured streaming + checkpointing. -> CDF ETL to get into the silver layer. Flattened out for the purpose of our vector database. Everything else uses pyspark. 

MariaDB -> s3 landing zone is in databricks using cursor-based ETL. Upsert into bronze tables. Structured streaming using autoloader. foreachbatch with merge to upsert data, with autoloader. In the landing zone they are parquet format. 

Reading into change data feed for silver layer SQL files using SQL warehouse. 

Look at the actual workflow running the pipeline. 

Process of initially loading all mariadb data straight into databricks is not practical. We are simulating data ETL by doing a copy of bronze dev catalog tables into our staging catalog. bronze ETL is running daily into dev catalog. 

mariadb to landing zone using pyspark mariadb connection. 20 minute step + 15 minute step that would be similar in production. 

Partitioning. Using liquid clustering on bronze tables by network_account_type_id. A lot of the logic is split up by network. 

benefits of writing 5 in parallel. with newer runtimes and liquid clustering in place. with partitioning, guaranteed 

Calculate ahead of time. Create table if not exists in the same step. 

dbt makes merge really clean but creates a temp table

# nov 22 standup

- testing search refresh every time a button is clicked. william is testing for overhead. 

final batch is being updated for tiktok. using on demand instances. 

anj: what needs to be done by monday. sagar post ingestion completed today. rag and summaries is left. wants a followup after lunch today with cyrus and sagar

sagar: uploaded summaries to qdrant is very quick, within an hour. 

anj to ryan: give a number of how many summaries are completed. it's okay if we don't have all data by monday

ryan: adhoc request from anj for ryan CEO; sagar asked for validation on cippus (current code is not adequate. took 2 hours for tiktok accounts). sagar to ryan - just take sample of 10-15% and check if those look good. qc of summary completion is handed off to cyrus. 
sushant suggested to ryan to use pandoc to programmatically created typesetted PDFs. 

sushant: daily orchestration of end to end bronze and silver incremental will start from todya. 

alex: new non-search ticket migrating something from java to databricks. 

anj: wanted to get all done by monday, but might be behind on summaries. wants as many summaries as possible for instagram. product team is going to checkin today to determine whether we should send out email on monday or not. 

sagar: will fix empty string problem on qdrant side today, so william doesn't have to do anything
