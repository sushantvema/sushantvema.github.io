---
title: "2025 Journal"
description: "Master thread for daily tracking in the year of 2025"
author: "Sushant Vema"
date_created: "2024-12-16T09:08:41"
date: "2024-12-16T09:08:51"
publish: false
tags:
  - "agenda"
---

# Monday December 16th

- sushant + alex: code review on few remaining improvements to e2e silver ETL. starting network account qdrant ingestion dev and cippus qdrant ingestion dev today afternoon
- sagar: started ingesting facebook summaries. quick look back at the in-house inference solution
- bruno: scaling qdrant from the backend, from the EKS side. setup a meeting with Karim. support tickets haven't been updating since last week.
- william: ticket with UI refinements got merged into dev.
- cyrus: figured out issue with facebook. one request that kept failing over 2-4 launches. ran just that one request and it took 8 hours to complete, and still failed. account that had english bio with posts in thai. each post was humongous. for now remove that account and relaunch. working on integration into ETL for summaries and embeddings. touch base with ryan about tomorrow meeting. introducing andres onboard. discussing with ryan sentiment analysis work. cleaning jira.
- anj: let's get performance tuning working before we put more into facebook. maybe we should start with all networks disabled instead of all networks enabled? couldn't find the batch api for grok for the transcription demo I showed. per campaign maybe 10-20k requests. individual calls are better since complexity is lower. we need to do performance improvement or commit to a savings plan before Taylor leaves for holiday on Thursday. There may be room for reducing 2 nodes (~20%). we can manage with 8 node for some time. Databricks contract is being pushed for them to come back with a better proposal. Someone from Publicis who's the Pub account manager in Databricks hasn't responded yet. anj out in the week of 24th, returning on the 6th
- sagar: wouldn't raise hopes for downwsizing since we are adding more memory. we can go on the savings plan right away. what we will have to do is relay a blueprint (different machine types, configuration types) to qdrant. in the current setup we wouldn't be able to downsize right now. tmrw meeting with qdrant. if we want to have a unified logging / dashboard: do we have an appetite to setup a solution? cloudwatch is expensive. start moving logs from cloudwatch to the new platform. Looky? backend would be s3 bucket. it has its own proprietary technology for building fast indexes.

- last night another end to end test with code from Alex's branch. workflow: [workflow](url)
- going forward, we only run the one-time scripts in staging. test out changes in one-time scripts only in staging.
- can we specify the write permissions of a delta table?
- Use staging as dev, leave dev alone
- when we have separate workspaces, each workspace will only have access to its catalogs
- alex made the commit change to go back to CTINE for all of the one-time ones. Copied all of the dev code to staging scripts.
- [x] DONE: when we reference functions, they are in the dev catalog.
  - Alex duplicated the dev functions and put them into staging
  - removing the catalog name from every function call
  - alex created duplicate functions for each catalog
- place the drop search index task in the test e2e one time ingest workflow
- alex realized that the bronze incremental was taking longer because the landing zone had incremental files from previous runs. landing zone is just a bucket in s3
- alex: check pricing of the dev landing zone bucket. there's a specific CLI to run to find out cost per bucket. this involves each bucket having cost allocation tags in the cost explorer.
- for repairs, we have to do it from the parent workflow. it will only run all of the failed child tasks. also works for ForEach tasks
- Alex switched the backup tasks from general purpose cluster to a Job Cluster with 1-4 workers. Uses
- Currently the mariadb snapshots are only accessible from one availability zone. Therefore there is another ETL job cluster that is us-west-2a
- WILLNOTFIX: exception handling changes with databricks LTS versions. Not reproducible yet. No good explanation to say to Databricks
- default configuration for a job cluster uses databricks fleet clusters. This saves costs, but does not make benchmarking consistent
- TODO: Vacuuming, cleanup, and data retention
  - What do we need to maintain history on? Some capabilities
- The reason why we didn't use Structured Streaming is because we were merging multiple source tables
  7
- testing the reading of custom latest version parameters in a separated workflow
- changed all of the CDF code to match the pattern of casting the parameter marker

# Tuesday December 17th

- Tested out improved incrmeental logic for the flat tables in dev catalogs. Did it yesterday in
- ryan: sentiment extraction with cyrus. top 5% manual analysis - influencer vs busniness.
- cyrus: focus is on summaries, etl stuff is getting delayed
- bruno: qdrant doesnt' have an answer about something.... databricks permissions issues today.
- anj: wants to see if reporting part can be picked up by the data team. cyrus:
- ryan: certain accounts are missing from the radius platform. maybe a non-issue
- sagar: fullstory might be able to give insight to sagar about all of queries people ar using. we may not be storing the http urls in cloudwatch.

- ryan: account comes up, but then says accounts not found. just checking to see what exists there are / left ot process. if they're in our system, they're in our system. Just trying to see if within each n-tile there are splits of brands v nonbrands.
- for some reason in a workflow it doesn't work.
- get the silver layer completely done before breaking for the holidays

- alex had to make some changes to the incremental file

# Wednesday December 17th

- [] TODO: Get Natalia the code for powerpoints extraction.
- [x] WILLNOTFIX: Fix "silver_etl_get_latest_versions_of_source_tables" to properly validate the things
  - found alternative solution to avoid this
- [x] DONE: Complete essay for History 31 and submit it to professor ASAP
- [x] DONE: Submit change of domain emphasis form
- [x] DONE: Update the last paychecks data for influential
- [x] DONE: Sign off on Anusha's invoice for AlixPartners

- Natalia: Get her the code for powerpoints for her to pickup the workstream

- alex + sushant: addressing a case in silver ETL where the last processed version + unprocessed versions get upserted every day. it should be only the unprocessed versions get upserted every day. implemented some complex logic in an upstream notebook task that modifies the task value references in the workflow to use the last processed version + 1 if there are >=1 uprocessed versions remaining in a source table. Hoping to start qdrant ingestion tasks today.
- bruno: review command execution with sagar and bastion. continuing to investigate databricks permissions issue. bruno might not be back to fulltime when Taylor leaves.
- Taylor: Environment setup related to databricks
- Cyrus: Still running Facebook summaries. 100000 facebook summaries processed thus far. Another 250000 more to go. Reverting attention to sentimen analysis stuff. Looks like we can't use the hand-coded data for finetuning because it's full of errors. Therefore the bar is low for a better workflow. Their handcoded sentiment analysis is pretty garbage. Ran the model on a sample of 1000. Run it again with sample of 10000. Have ryan re-encode ones with divergence with the model. Most of the day today. Meeting about briefings with Andreas to onboard him further.
- Ryan: all caught up. There was discussion with top 5% stuff. Go through tickets in review and do handoffs.
- William: Worked with Alyssa to get metrics about radius loading time in Fullstory.
- Anj: For the 5% there is a meeting. How many brand accounts are being used. We can look at lists to see how frequently they are utilized. Cyrus: Kat and Mack don't want us to drop any brands. Anj: if they're searching and not adding to lists, what's the point of searching. Cyrus: can we identify accounts that haven't been active recently? we have lots of accounts that are just not active which we either remove or not ingest. Ryan: two step process - search instagram first, then go to google to get any context about being a brand or an influencer.
- Anj: Before Taylor goes, we are going to do the savings plan. We can't downsize, so we need savings plan. Even Sagar doesn't have downsizing protocol in place yet. Bruno: we should go to savings plan to begin with. Taylor should do it today. Cyrus: are these reserved instances? Taylor: We prepay for instances, big discount (25%). For 1 year there's a discount, for 3 years there's even more discount. After the savings plan, we just use the reserved instances. January hopefully should be on Publicis contract in January. Publicis has a 0% support deal (0% of their monthly cost). We pay around 3-5% of our monthly cost

- Figured out google meet slack integration
- Last week's DBX checkin was mostly about demand planning. It's using jupyter notebooks.
- .sql files are preferred because we can wrap it with the pyspark sql runner.
- do we need to refactor the locations of the sql query files.
- Use Pathlib for path creation
- We should try to see if we can use a relative path first.
- there's dbutils.widgets.get_all()
- Do we have to split the query file?
- We can remove the target_catalog parameter
- better monitoring in the sql warhouse because you can see the query profile. in a job compute with pyspark, it would be much cheaper.
- sql pro vs sql classic compute.
- using the pricing calculator in databricks.
- medium warehouse is 13xlarge.

- Databricks infra-related questions.
- One thing we've discovered is that we're using change data feed for incremental ETL between bronze and silver layers. We need to merge together the newest CDF data from multiple source tables. Hard to do with structured streaming.
- We are storing the latest processed version from each source table into table properties of the target table.
- table_changes would error if you try to put in a larger version
- spark configuration timestamp out of range enabled that returns an empty result if you use a version that's newer than the latest version.
- This is not supported in SQL warehouse. therefore we want to switch to using pyspark instead. if we do it in pyspark, we're trying to match our job compute to our warehouse size
- sql pro medium would be i38xlarge with 8 workers.
- is there a way to do this in sql warehouse. what's your advice if we want to do it in a job compute but match the performance of the sql warehouse.
- another option is we do some validation in a notebook upstream to check if the version + 1 exists or not. if the version doesn't exist, we would programmatically provide an empty result.
- tian suggests delta live tables to keep track of these changes. checks the versions beforehand
- each source table might not be updated on a daily basis. if there is a version change, we want to incrementally update those changes
- sql warehouse doesn't open a lot of avenues to tune those spark configurations. they maintain a tight timeline
- other option is using a job to do that. need to enable photon. for sql pro it uses i3, serverless uses "best versions."
- used to have an option in sql warehouses to choose cost effective vs reliable. we save from EC2 side of it
- we know we need something reliable, but if it's a long-running process , workers might be terminated. happens a lot around 5 PM pacific.
- tian: people tend to use non-business hours to run batch jobs.
- built a lot of optimization mechanisms in the sql warehouse.
- probably want to use the latest runtime for the sql queries. in our workflows we use a newer runtime. we have some all purpose clusters using older runtimes.
- can SQL have if/else logic to do table changes
- how to support tables that don't have new changes while

- new idea: filter out the latest processed version using a simple and statement in the where clause
- draft PR is usually when something needs to be reviewed before it is merged. or someone else needs to work on that branch and you need to make it a draft to log the current state. when the code development is completed but not fully tested yet.
- brackets with ticket name per PR. there's already an automation to link jira tickets
- that might trigger some automations. might change ticket status based on PR being merged.
- would put jira ticket as ready to review status.
- should be moving to a PR per ticket approach. in that case, put the ticket prefix and commit names, should show up in jira ticket itself.
- that would be in line with how software development team does stuff.
- we've been stuck with initiative, epic, and tasks.
- can we edit PR names in retrospect?
- can add in github review groups
- .sql files in the software development team for example has Alex as a reviewer by default.
- merge PRs descriptions and titles can be edited
- the art of doing twice the work in half the time - book recommendation by alex
- example of reading and writing from/to kafka and unit test with mock data
- stay away from chispa because it's not widely used (yet)
- unittest solution vs pytest solution
- delta live tables lets you have a development mode - when it fails you can keep the compute running.

- will run the three workflows to run for errors.
- what else is remaining before another end-to-end?
- eventually run through different

- all succeed is important because it needs to have all of the dependencies successfull. without the all succeeded task, if any of the dependences failed, it would be in a status called success with failures.
- success with failures allows for downstream jobs to continue
- DONE: should schema evolution be enabled by default? should be turned off
  - Turned it off by default. An error will be thrown if an upstream schema changes
- clustering amazon s3 cache might require a support ticket to get it scoped

# Thursday December 19th, 2024

- Ryan: Sentiment analysis manual annotation. Meet w Andres for briefing process live dmeo. Documentation review. Handing off to Andres.
- Sushant and Alex: Yesterday we did an end to end. Ready for uninterrupted end to end today. Incremental flat table scripts daily scheduling is coming up. Keep that running daily. Simulate the incremental strucured stream with a framework that allows to specify start and end dates. Few days of incremental updates needed to simulate that buffer. end-to-end ticket will be closed out today
- Cyrus: facebook summaries, integration. sentiment analysis.
- Bruno: Implemented Bastion's intructions for scaling down the cluster. To review with Bastion and Sagar, will do after holiday. Continue databricks permissions issue.
- Taylor: Created databricks production environment yesterday. Need eyes for review @alex. Taylor made a managed instance, but we don't want a managed VPC. Taylor will redo it today.
- William: no search updates

- have some free time to work on alixpartners stuff. using neovim as much as possible.
- maybe I can run a deedi instance in my AP laptop and push changes, reloading the instance in real time
- learned about vim jumplist (leader sj enter)
- extractor page: select_single_contract and select_batch are not being used right now

- Today I wasted a lot of time dealing with self-imposed python environment issues.
- Cyrus and Anj both scheduled one-ones with me tomorrow. That sounds foreboding.
- Trying to debug streamlit. ipdb breakpoints work
- streamlit run app.py server.headless true -> allows not opening a new browser every time

# Friday December 20th, 2024

- [x] TODO: Share notes with Sagar about qdrant ingestion

- Alex: moving off of end-to-end to scheduled incremental. Moving on to DS-309. Have to get production tables going in the day.
- Sushant: TODO: change all ETL job clusters to on demand. Will be working at least 3 days next week, will coordinate with Alex
- Alex and Sushant: independently coming up with design doc for qdrant ingestion architecture. to review with sagar this afternoon
- Sagar: last phase of getting the advanced queries from Abby. asked william about graphql resolvers. does every request create a new qdrant connection? performance testing script should follow the same pattern. afternoon, turn on indexes in production.
- Ryan: Continue with sentiment analysis today. Sagar will meet to review 280 QC. sentiment analysis and/or adhoc requests today.demand
- Cyrus: Processing summaries as usual. Large batch that is about to finish, will pass on to Sagar. ~130-150k. RAG integration started, probably a week of dev time required on it. Sentiment analysis - review ryan's work towards end of day. Get MVP for Alex before New Year.
- Bruno: Continue working on databricks permissions testing. Cluster scaling - put together scale down plan to review after holidays.

- Working at least 3 of those days next week
- two month part time contract. get the contract and apply pressure
- You can keep working at a less amount. Will talk to Anj and see if we can get a stopgap going.
- Alex wont's be working over break. Cyrus will be available. Making sure these facebook
- facebook is 10x longer than youtube
- running loops with the older sdk

- mini performed better than 4o. Closer to human aligned.
- 700/200000 had a discrepancy between
- either humans struggle with this or AI struggles with this.
- nearest neighbors search against
- end model will be a finetuned GPT. same api to load batches as using batch api.
- 3 successful models for
- these comments are not in cippus. exist in a data service called export comments API
- out of 2000 comments, the human is garbage. only 80 that the
- brifing project was so bad.
- excel report has to be created by Alex
- EMR clusters in AWS
- cyrus used Amazon Glue to convert all files to Glue tables.

- architecture diagraming with Alex, sentiment analysi
- no status change on the fulltime conversion
- there is a budget supposed to come from publicis that is supposed to come. hoping to be done by this time
- conversion request already shared with them
- put that in the same thing
- extend by three months, reducing the hours, increasing the compensation per hour
- katherine about benefits
- right now payment is hourly
- anything below 50 hours per week is not questionable.

# Sunday December 22nd, 2024

- Working on extractor enhanced citations
